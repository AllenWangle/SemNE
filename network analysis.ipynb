{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络的部分拓扑指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======CN网络的拓扑指标数据=======\n",
      "网络节点数：\n",
      "58687\n",
      "网络边数：\n",
      "69941\n",
      "网络同配系数：\n",
      "-0.047738548328753724\n",
      "=======ECCI网络的拓扑指标数据=======\n",
      "网络节点数：\n",
      "27164\n",
      "网络边数：\n",
      "31538\n",
      "网络同配系数：\n",
      "-0.09413127616141441\n",
      "=======PB网络的拓扑指标数据=======\n",
      "网络节点数：\n",
      "49874\n",
      "网络边数：\n",
      "117482\n",
      "网络同配系数：\n",
      "-0.10960592614683765\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path = \"Dataset/\"\n",
    "data_dir = os.listdir(path)\n",
    "for d_d in data_dir:\n",
    "    net = d_d + \".train.txt\"\n",
    "    G_train = nx.read_weighted_edgelist(path + \"/\" + d_d + \"/\" + net,nodetype=int,create_using=nx.Graph())\n",
    "    print (\"=======\"+ d_d + \"网络的拓扑指标数据=======\")\n",
    "    print (\"网络节点数：\")\n",
    "    print (len(G_train.nodes()))\n",
    "    print (\"网络边数：\")\n",
    "    print (len(G_train.edges()))\n",
    "    print (\"网络同配系数：\")\n",
    "    print (nx.degree_assortativity_coefficient(G_train))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语义信息的平均长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======CN网络的语义信息平均长度为======\n",
      "2.7895615724095624\n",
      "======ECCI网络的语义信息平均长度为======\n",
      "2.584850496790952\n",
      "======PB网络的语义信息平均长度为======\n",
      "2.341830908086204\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "index_len = []\n",
    "\n",
    "path = \"Dataset/\"\n",
    "data_dir = os.listdir(path)\n",
    "for d_d in data_dir:\n",
    "    file = d_d + \".index.txt\"\n",
    "    with open (path + \"/\" + d_d + \"/\" + file,\"r\") as index:\n",
    "        for line in index.readlines():\n",
    "            index_len.append(len(line.strip().split(\"\\t\")[1].strip().split()))\n",
    "    print(\"======\" + d_d + \"网络的语义信息平均长度为======\")\n",
    "    print(sum(index_len)/len(index_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 统计语义网络的离散程度（A-B,A中单词是否出现在B中，如果是，加1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======CN网络的离散程度为======\n",
      "0.06383952188272973\n",
      "======ECCI网络的离散程度为======\n",
      "0.6201407825480373\n",
      "======PB网络的离散程度为======\n",
      "0.03364770773395073\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def ChageIDtoSem(edge,index):\n",
    "    return index[edge]  \n",
    "\n",
    "path = \"Dataset/\"\n",
    "data_dir = os.listdir(path)\n",
    "for d_d in data_dir:\n",
    "    net = d_d + \".train.txt\"\n",
    "    file = d_d + \".index.txt\"\n",
    "    g = nx.read_weighted_edgelist(path + \"/\" + d_d + \"/\" + net,nodetype=int,create_using=nx.Graph())\n",
    "    ind = {}\n",
    "    with open (path + \"/\" + d_d + \"/\" + file,\"r\") as indf:\n",
    "        for line in indf.readlines():\n",
    "            ind[int(line.strip().split(\"\\t\")[0])] = line.strip().split(\"\\t\")[1]\n",
    "        \n",
    "    edge_str = []\n",
    "    for edge in g.edges():\n",
    "        edge_str.append([str(ChageIDtoSem(edge[0],ind)), str(ChageIDtoSem(edge[1],ind))])\n",
    "    \n",
    "    count = 0\n",
    "    for e in range (len(edge_str)):\n",
    "        for i in edge_str[e][0].split():\n",
    "            if i in edge_str[e][1].split():\n",
    "                count = count + 1\n",
    "                continue\n",
    "    print(\"======\" + d_d + \"网络的离散程度为======\")        \n",
    "    print(float(count/len(g.edges())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
